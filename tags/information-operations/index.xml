<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Information Operations | CogSec Collaborative</title>
    <link>https://www.cogsec-collab.org/tags/information-operations/</link>
      <atom:link href="https://www.cogsec-collab.org/tags/information-operations/index.xml" rel="self" type="application/rss+xml" />
    <description>Information Operations</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>2020© Cognitive Security Collaborative</copyright><lastBuildDate>Sun, 13 Sep 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Information Operations</title>
      <link>https://www.cogsec-collab.org/tags/information-operations/</link>
    </image>
    
    <item>
      <title>Distributed Defence Against Disinformation</title>
      <link>https://www.cogsec-collab.org/post/distributed-defence-against-disinformation/</link>
      <pubDate>Sun, 13 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://www.cogsec-collab.org/post/distributed-defence-against-disinformation/</guid>
      <description>&lt;p&gt;I spoke recently at Disclosure — a conference started by Marc Rogers, bringing together interesting systems thinkers across information security. Last year, I spoke about how to adapt infosec to disinformation defense; this year about what the CogSecCollab leads have learnt from running the CTI League’s Disinformation response team.&lt;/p&gt;
&lt;p&gt;2020 is where cognitive security, the idea of treating disinformation as an infosec problem akin to malware, really caught on. First, let’s talk about definitions. Misinformation is false content. In disinformation, the content doesn’t have to be false — some of the best disinformation campaigns use mostly-true information twisted out of context, mis-attributed, inorganically amplified etc etc. What interests our teams are attempts at large-scale belief change or emotion change, that mislead people about the content or context of information.&lt;/p&gt;
&lt;h1 id=&#34;2020-not-your-grandmas-disinformation-ecosystem&#34;&gt;2020: Not your Grandma’s Disinformation Ecosystem&lt;/h1&gt;
&lt;p&gt;The League concentrates on Covid19-related disinformation. It’s useful to talk here about narratives, because there are far less narratives than messages, making them easier (especially with text-based machine learning techniques) to track. The League team keeps a list of hundreds of Covid19 narratives, bucketed into top-level categories from origin myths (‘escaped bioweapon’), covid isn’t serious, medical scams (covid cures including MMS and alcohol), resolution (‘country X has a cure already’), to crossover narratives. In 2020, we saw a lot of Covid19 crossover narratives, where existing groups like antivaxxers and hardcore rightwingers met and joined forces, and conspiracy theories were recycled and combined into new narratives. We loosely grouped crossover narratives into conspiracies (5G, antivax, depopulation, black helicopters), freedom rights (anti-stayathome, second amendment, immigration, etc), and geopolitics (covert and overt from China, Iran etc, “blue check” accounts), and expect this type of recycling to become normal.&lt;/p&gt;
&lt;p&gt;If you want to understand disinformation, you need to understand the motivations. Geopolitics (follow the countries), power gain (follow the divisions), financial gain (follow the money), attention seeking (follow the sharks, satire and other LOLs), and online discussion (follow the opinions, conspiracies, protest, nazis etc). In 2020, despite all the news about geopolitical disinformation, a lot of the disinformation we tracked was financially-motivated. In a lot of the incidents we tracked, we found people trying to make money — either originating, or attaching themselves to incidents. Etsy and Amazon shops selling t-shirts, more sophisticated sales operations selling “cures”, networks of websites selling advertising space. There are crossovers here too: we tracked one Covid19-related incident back to someone selling their book about 5G.&lt;/p&gt;
&lt;p&gt;Money usually needs URLs. If you’re making money online, at some point you’re going to need a URL: the Etsy or Amazon shop, or your own domains that you can control sales through, sell advertising space on, collect user details to sell etc. An example of this is The NaturalNews network — interesting because it started as a healthcare misinformation site, then broadened out — for example, we found it amplifying the antifa on buses story this year; and useful because they track the zeitgeist of current disinformation. If you’re tracking disinformation, URLs become important because they help you find more of it: a URL is an entry point into a network, from which we can map out a network of domains, associated social media, linked disinformation campaigns etc. We’ve done well with tools like domaintools, backlink checkers, and Builtwith, finding related sites through registrations, google analytics, and advertising tags.&lt;/p&gt;
&lt;p&gt;Disinformation evolved in 2020. Some examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We tracked WeWontStayHome because it was part of the wider Covid19 health incident. It was a small incident, but it seeded a much larger incident, OperationGridlock, later. We also saw this incident spread across countries and states. This was an early use of astroturfing: creating and populating a group for each state.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When we created the AMITT framework for tracking disinformation techniques, we included “going physical” as a category because even though it was rare then, we thought it might become important. In 2020, a lot has gone physical, including “face mask exemption cards” — laminated cards intended to exempt their bearers from covid19 mask requirements in stores etc. We’ve seen a lot of homespun ideas, in this case a card with a long spiel, HIPAA misspelt etc, being picked up and productionized either for money, to support other campaigns or both (e.g. the main site that productized mask exemption cards takes PayPal donations, and collects user details). We’ve also seen this cross countries and communities, e.g. a more professional-looking mask exemption card in Canada, listing organizations targeting parents.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;2020 isn’t all bad: it’s a breakout year for countermeasures too, from the kPop fans flooding extremist hashtags with boy band images, to social media companies starting to take down content that isn’t just immediate threats to life. It’s also been a good year for homegrown countermeasures, like mask exemption override cards: laminated cards that ‘cancel’, game-style, mask exemption cards.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Disinformation doesn’t exist in a vacuum: it’s part of an information space. If you just remove the disinformation, you leave vacuums, voids in the places where people search for information. People will still search: if you remove the wrong information, you need to have information or routes to information in ways that they can consume it, in the places that they want to consume it. Many good information teams emerged in 2020 — the League team has partnered with one of them, the RealityTeam, working out how they can rapidly deploy counter-narratives and information, in response to new incident narratives.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Some developing-world spam and marketing companies are pivoting to provide disinformation as a service — RecordedFuture did a good report on this, and the use of a fake NGO in Ghana to target African Americans was interesting. Disinformation is starting to get the attention of organized crime (there’s a UNODC report out on this soon), but the economics aren’t there yet: at the moment, ransomware is a better business model for large amounts of money, and businesses and principals are mostly caught up in disinformation campaigns rather than targets of it. Deepfake tech is still too complicated and expensive to massively scale, but it’s coming. We already have text, and the next evolution is to more video and voice. The likely business transition is from small specialized agencies, e.g. a boutique capability, then market expansion where disinformation becomes a commodity capability.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That’s where we are in 2020, but CogSecCollab always looks ahead. We do this from a combination of responding to disinformation as a Blue Team (running a response plan, building playbooks, tracking campaigns, incidents, narratives and artifacts), and learning from examples by running weekly Red team exercises. Topics we’ve covered in those exercises include running a “disinformation as a service”/alternative marketing company, running a hostile social media platform, mixing disinformation with coordinated sensor spoofs, and extending an existing narrative (e.g. anti-medical safety). We learn a lot from these. Sometimes they give us a heads-up on likely next steps in disinformation campaigns (e.g. potential disinformation narratives as children went back to school); other times we gain insights into how and why disinformation creators operate the ways that they do.&lt;/p&gt;
&lt;h1 id=&#34;2020-cognitive-security-is-real-now-join-us&#34;&gt;2020: Cognitive Security is real now. Join us&lt;/h1&gt;
&lt;p&gt;Cognitive security is a rapidly growing domain that interacts with cyber and physical security, and includes things like information operations and disinformation. We look at this from a set of overlapping axes.&lt;/p&gt;
&lt;p&gt;Collaboration. “This isn’t a silver bullet problem, it’s a thousand-bullet problem” — Pablo Breuer. Disinformation is a distributed, heterogeneous problem. It needs a similar response, one that’s collaborative, heterogeneous and connected. Lots of different groups at lots of different scales, that have to work together, and we need to connect them, in a way that respects the groups, the subjects of disinformation, and the accounts and groups being investigated. Practically, that means privacy, sharing, and standards.&lt;/p&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/distributed-defence-against-disinformation/pyramid_hu5decbe907254ad1bca668baed9e2a213_42459_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Misinformation Pyramid&#34;&gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/distributed-defence-against-disinformation/pyramid_hu5decbe907254ad1bca668baed9e2a213_42459_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;682&#34; height=&#34;472&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Misinformation Pyramid
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Layers. We’ve written about this model before: Longer-term campaigns (antivax, destabilize national politics etc), containing shorter-term incidents (e.g. a burst of activity around a specific topic or event), based on narratives, (the stories we tell ourselves about who we are, who we belong to, who we don’t belong to, what’s happening in the world), which show up as artifacts: messages, images, accounts, groups, relationships.&lt;/p&gt;
&lt;p&gt;Threat intelligence Tasks. We’re doing threat intelligence — we want to find, predict and neutralize current and future threats.That rests on intelligence skills — assessing the situation picture using the five Ws (who, what, when, where, why, and how): what’s happening, with best guesses about origins and future moves; who’s involved (including attribution), why (intent), and how (tactics and techniques). For disinformation, this is usually OSINT (open source intelligence) — finding that situation picture using publicly-available data, supported by data science — finding patterns in big data that’s arriving fast across many channels (as Marc Rogers noted last year, the 3V volume, velocity, variety model is what makes modern disinformation tracking different). Attribution — working out who’s responsible for a disinformation incident — is hard. You don’t have full access to data, and there are incentives for people to obfuscate and hide who they are. At best, attribution is probabilistic, but even a hint can help us assess potential moves, and countermoves.&lt;/p&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/distributed-defence-against-disinformation/analytics_maturity_model_hu19645939a369c7090f0da298d438b5b5_101882_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Data Science Ladder (from https://www.ecapitaladvisors.com/blog/analytics-maturity/)&#34;&gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/distributed-defence-against-disinformation/analytics_maturity_model_hu19645939a369c7090f0da298d438b5b5_101882_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;700&#34; height=&#34;378&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Data Science Ladder (from &lt;a href=&#34;https://www.ecapitaladvisors.com/blog/analytics-maturity/&#34;&gt;https://www.ecapitaladvisors.com/blog/analytics-maturity/&lt;/a&gt;)
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Analytic maturity. The data science ladder also applies to disinformation response: work ranges from assessing what’s happened (e.g. traditional statistical analysis), to predicting what might happen next (machine learning), to moves and countermoves in an interactive environment (applied game theory). Disinformation response has been moving up this ladder, and is currently around the prescriptive analytics point on it.&lt;/p&gt;
&lt;p&gt;Response timescales. There are different team response timescales: strategic (weeks/months/years), issue-focussed work, e.g. long-form journalism exemplified by Stanford Internet Observatory, U Washington, Shorenstein Center, Bellingcat, DFRlab, Grafika and social media platforms; operational (days/weeks), project-focussed work that’s usually embedded with development teams working in AI/ML-based disinformation data and tool companies; tactical (hours/days), incident-focussed work, responding to disinformation as it happens, exemplified by the New York Times, CTI League, some of MLsec, and the crisismapping teams that cover disinformation. Each of these work differently. If you have hours, all you care about is stopping the flood of disinformation; if you have months, you can get into attribution, geopolitics and motives. In 2020, many of the strategic groups started responding faster and became more tactical.&lt;/p&gt;
&lt;h1 id=&#34;disinformation-incident-response&#34;&gt;Disinformation Incident Response&lt;/h1&gt;
&lt;p&gt;This isn’t a new problem: I’ve addressed it before. As a crisismapper, I set up procedures for data analysis and sharing in reaction to sudden-onset disaster events, set up and connected groups doing this around the world. These activities map to disinformation too.&lt;/p&gt;
&lt;p&gt;We’re tracking Covid19 incidents through the &lt;strong&gt;CTI League&lt;/strong&gt; disinformation team. The League is the first Global Volunteer emergency response Community that defends and neutralizes cybersecurity threats and vulnerabilities to the life-saving sectors, related to the current COVID-19 pandemic. The disinformation equivalents of the League’s main work are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Neutralize&lt;/strong&gt;: Disinformation incident response: triage, takedown, escalation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Clearinghouse&lt;/strong&gt;: Collate and share incident data, including with organizations focusing on response and counter-campaigns.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prevent&lt;/strong&gt;: Collate disinformation indicators of compromise (IoCs) and vulnerabilities; supply to organizations.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Support&lt;/strong&gt;: Assess the possibility of direct attack, and ways to be ready.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The rest of this post is about the incident response part of that. To do this, we need the usual process triangle of people, process, technology and culture:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Enough trained people (understand disinformation, understand threat response) to be able to respond fast enough and make a difference to an incident (that includes noticing incidents in time to respond)&lt;/li&gt;
&lt;li&gt;Enough ways to make a difference (including outbound connections)&lt;/li&gt;
&lt;li&gt;Safety culture including mental health and OPSEC&lt;/li&gt;
&lt;li&gt;Fast, lightweight response processes&lt;/li&gt;
&lt;li&gt;Technology —to support and speed up analysis, storage etc&lt;/li&gt;
&lt;li&gt;Sharing technology — to get data to responders in ways they understand&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CogSecCollab has been working on processes, tools, and training to support this. We started with the disinformation adaptations we made to threat intelligence tools (HIVE and D3PO for case tracking, MISP for intelligence sharing, and data tools for analysis support): the MISP work in particular is already shared with team in NATO, the EU and other countries. We’ve also been cleaning up the CTI League disinformation process manual, and are starting to share that with other groups for comment/ improvement; after that, we plan to share our team training courses (e.g. Data Science for Disinformation Response — a repurposed university course).&lt;/p&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/distributed-defence-against-disinformation/ooda_hu4295dd89ab1e45309c9b7dc97c72699a_114107_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;John Boyd’s OODA (Observe, Orient, Decide, Act) Loop&#34;&gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/distributed-defence-against-disinformation/ooda_hu4295dd89ab1e45309c9b7dc97c72699a_114107_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;700&#34; height=&#34;362&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    John Boyd’s OODA (Observe, Orient, Decide, Act) Loop
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Almost four years ago, I started talking about the overlaps between disinformation, information security, machine learning, and military competition short of armed conflict, and used Boyd’s OODA diagram then. For Boyd, it was about understanding why some pilots were better at winning dogfights, couched in terms of interacting decision loops. In 2020, that’s still a useful way to think about the pieces we need in a response.&lt;/p&gt;
&lt;h1 id=&#34;observe-2020s-decade-of-tracking-covid19-disinformation&#34;&gt;Observe: 2020’s Decade of Tracking Covid19 Disinformation&lt;/h1&gt;
&lt;p&gt;CTI gets feeds in from other groups, from its own monitoring and from its own members. Most alerts start with an artifact: an image, a URL, a piece of text. First, we have to decide whether to treat this as an incident. The three big questions we ask are about the potential harm from this incident, whether it’s disinformation, and whether we’re the best team to respond to it. For harm, we look at harms frameworks, and think about what the potential effects of an incident are, its size, coordination and targets. On disinformation, we ask where the falsehood is (e.g. is this misinformation or disinformation, are these fake groups, profiles, amplification etc), and whether it’s a different type of falsehood, e.g. phishing. On whether we’re the best team to respond, we ask if it’s in our area (e.g. covid19), whether other teams are already tracking and responding, if we have the resources to respond (this is long-haul work: burning out teams is bad), and do we have a reasonable chance of doing something useful about the incident. When assessing, we also look at the information we already have. For instance, we see a lot of repeat offenders, so we look for things like known medical scams. No team works alone, so even if an incident isn’t responded to, best efforts should be made to get alerts out, if needed.&lt;/p&gt;
&lt;p&gt;Once we start an incident, our first job is to gather enough information to determine whether we should act, hand this information over to another party, stand down, or not act but keep a watch on this area. This is usually a mixture of artifact-based activity analysis, network analysis and fact-checking:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Activity analysis: Tracking artifacts (messages, images, urls, accounts, groups etc), e.g. finding artifact origins, tracking how an artifact moves across channels/groups etc, and finding related artifacts. Detecting AMITT Techniques, e.g. detecting computational amplification; detecting, tracking and analyzing narratives.&lt;/li&gt;
&lt;li&gt;Network detection: Finding inauthentic website networks (pinkslime). Finding inauthentic account and group networks (including botnets).&lt;/li&gt;
&lt;li&gt;Credibility/ Verification: Fact-checking: verifying an article, image, video etc doesn’t contain disinformation. Source-checking: verifying a source (publisher, domain etc) doesn’t distribute disinformation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(This is the incident-based tactical work. We also need monitoring work — spreader analysis — looking for infrastructure and accounts that are set up in advance of incidents, including sock puppet accounts “laundered” and left to mature).&lt;/p&gt;
&lt;p&gt;Volume, Velocity, Variety: we can’t do that quickly enough with humans alone. We have to speed that up with machines, and here are some of the places that can be done.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Graph analysis: finding super-spreaders, finding rumor origins, uncovering new artifacts, tracking movement over time&lt;/li&gt;
&lt;li&gt;Text Analysis: finding themes, classifying text to narratives, clustering text to narratives, searching for similar text/narratives&lt;/li&gt;
&lt;li&gt;Image, video, audio analysis: clustering images, searching for similar images, detecting shallowfakes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CogSecCollab / CTI League Disinfo have already been using graph and text analysis, and experimenting with ways to cluster images so we can minimise the number of times we expose humans to sometimes-difficult images. This matters because exposure is cumulative, and if we can avoid exposing someone to 100 near-identical difficult images or texts, that’s useful.&lt;/p&gt;
&lt;h1 id=&#34;orient-getting-the-situation-picture&#34;&gt;Orient: Getting the Situation Picture&lt;/h1&gt;
&lt;p&gt;Here we come to sensemaking, or understanding what you observed, in context. This includes looking at what we’ve collected, to work out what’s happening and might happen across the whole incident. One way the League team does that is by analyzing the connections between incident objects, using MISP. MISP is an open source threat intelligence platform that we’ve repurposed from malware to disinformation (CogSecCollab runs the MISP disinformation community). MISP is built on STIX, the sharing standard used by ISACs and ISAOs. We extended this slightly for disinformation, adding object types for incidents and narratives, and using AMITT for the attack patterns (see 
&lt;a href=&#34;https://github.com/cogsec-collaborative/amitt_cti&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/cogsec-collaborative/amitt_cti&lt;/a&gt;).&lt;/p&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/distributed-defence-against-disinformation/plandemic_huef882820968890d4a09105691173e7e9_116471_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;AMITT TTP Framework, Plandemic example&#34;&gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/distributed-defence-against-disinformation/plandemic_huef882820968890d4a09105691173e7e9_116471_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;700&#34; height=&#34;361&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    AMITT TTP Framework, Plandemic example
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;We’ve talked about the AMITT Framework before. It’s how we break an incident into techniques that we can analyze and counter. AMITT is now embedded in MISP, and we’ve handed it over to MITRE to manage. We tick the AMITT boxes during observation. During Orient, we look at this diagram to work out what’s happening, how we might respond, and if we catch an incident early, which downstream techniques might be used in that incident too. (The example here is Plandemic — a debunked conspiracy theory video which makes some false claims about the nature of COVID-19. We mapped it in AMITT to help us understand what capabilities the actor has and potentially how they’re resourced.)&lt;/p&gt;
&lt;p&gt;What we get out of Orient is an incident report, containing a summary, narratives, techniques, artifacts and objects. We also get a MISP event that we can share with other groups either directly or by email, via their threat intelligence tools etc. We added a few other things to MISP for this: Object types for common social media platforms, and code to load these into MISP using single-line commands in Slack, because speed is everything in a tactical response; new relationship types, to make the graphs that users can traverse in MISP richer; and taxonomies (DFRLab’s Dichotomies of Disinformation, and a NATO-led tactical variant) to cover things like types of threat actor.&lt;/p&gt;
&lt;h1 id=&#34;decideact-options-on-countermeasures-mitigations-resilience-collaboration-interaction&#34;&gt;Decide/Act: Options on Countermeasures, Mitigations, Resilience, Collaboration, Interaction&lt;/h1&gt;
&lt;p&gt;After Orient, we Decide. In 2020, we stopped “admiring the problem”. Questions we now need to ask at the end of analysis include: What are our options? Should we act? Do we want to? What are the ways that we, and the people connected to us, could affect a disinformation incident?&lt;/p&gt;
&lt;p&gt;First, the who. Potential responders include the whole of society, including the infosec bodies already linked by the ISAOs and cyber Interpols. That’s platforms, law enforcement, government, elves (volunteer groups), the public, online and offline influencers, media, nonprofits, educators and corporations.&lt;/p&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/distributed-defence-against-disinformation/countermeasures_hu74ddd48492945c99b906660ce0040ee3_60542_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;One countermeasures view from https://github.com/cogsec-collaborative/amitt_counters&#34;&gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/distributed-defence-against-disinformation/countermeasures_hu74ddd48492945c99b906660ce0040ee3_60542_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;700&#34; height=&#34;451&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    One countermeasures view from &lt;a href=&#34;https://github.com/cogsec-collaborative/amitt_counters&#34;&gt;https://github.com/cogsec-collaborative/amitt_counters&lt;/a&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;And the what. In 2019, MisinfoSec worked on mitigations and countermeasures, building a course of action matrix from the AMITT tactic stages and a variant of the JP-3 list of effects: detect (find them), deny (stop them getting in), disrupt (interrupt them), degrade (slow them down), deceive (divert them), destroy (damage them), and deter (discourage them), or the TL;DR version: prevent access, break flow, add friction, honeypot, damage, and remove the incentives to create disinformation in the first place.&lt;/p&gt;
&lt;p&gt;CogSecCollab has built theory and examples for effects-based, tactic-based and doctrine-based countermeasures. The CTI League team is using effects-based counters: reporting to law enforcement, platforms, and registrars, with CogSecCollab helping to connect the RealityTeam counter-narratives group back to the CTI League.&lt;/p&gt;
&lt;p&gt;Having looked at options during Decide, it’s time to Act: make a change in the environment, and potentially start interacting with it. When you act in a disinformation space, you’re acting in an environment, with a lot of other humans and machines in. And what you can end up in is a multiplayer game, where you’re each acting in response to each other, and playing off against each others’ resources. Grugq, Pablo and myself have been working on this. But that’s for another discussion.&lt;/p&gt;
&lt;p&gt;That was a quick spin around CTI League disinfo and CogSecCollab in 2020. You can learn more about the teams at 
&lt;a href=&#34;https://cti-league.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://cti-league.com/&lt;/a&gt; and 
&lt;a href=&#34;https://cogsec-collab.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://cogsec-collab.org/&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Cognitive Security Collaborative: The First 6 Months</title>
      <link>https://www.cogsec-collab.org/post/the-first-six-months/</link>
      <pubDate>Tue, 30 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.cogsec-collab.org/post/the-first-six-months/</guid>
      <description>&lt;h2 id=&#34;the-cognitive-security-collaborative-the-first-6-months&#34;&gt;The Cognitive Security Collaborative: The First 6 Months&lt;/h2&gt;
&lt;p&gt;In 2019, the Misinfosec Slack group and Misinfosec Standards Working Group created bridges between the information operations, information security, data science and disinformation communities. We worked together, creating common vocabulary, processes, and a mapping onto disinformation needs of information security tools, techniques and processes that included the AMITT standard for describing disinformation incidents and ways to mitigate and counter them.&lt;/p&gt;
&lt;h2 id=&#34;one-community&#34;&gt;One Community&lt;/h2&gt;
&lt;p&gt;In January 2020, we merged into a single team: the Cognitive Security Collaborative(“Cogsec Collab”).  We continued work on countering disinformation campaigns, with a focus on building the tools, processes, and networks needed to create an effective collective, distributed response to the large-scale, distributed, asymmetric threat that is modern disinformation. In short, we wanted to see if we could build a worldwide equivalent to the Baltic Elves by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;making it possible to build response groups for free,&lt;/li&gt;
&lt;li&gt;sanely connecting together individual responses,&lt;/li&gt;
&lt;li&gt;connecting community alerts to responders, and&lt;/li&gt;
&lt;li&gt;connecting new response groups to the existing information security response system.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Our original goal was to focus on this work throughout 2020.  We are working with NATO, RRM Canada, and other groups toward this end.&lt;/p&gt;
&lt;h2 id=&#34;active-deployments&#34;&gt;Active Deployments&lt;/h2&gt;
&lt;p&gt;In mid-March 2020, as COVID-19 disinformation incidents started to rise, we were asked to build a community-based disinformation team (similar to the crisis-mapping teams of the 2010s) to provide surge capacity in data gathering and initial analysis.  In early April 2020 we were invited  to lead the Disinformation team at the CTI League - a newly-formed community of cyber threat intelligence (CTI) experts, incident responders, and infosec industry experts working to neutralize cyber threats that exploit the COVID-19 pandemic.  As a result, we pivoted from a focus on small-team management and Google Docs to building tools, process and structure for a group of 500 people representing information security, law enforcement, medical institutions, and ISP/media platforms. We’ve responded to dozens of incidents, ranging from medical scams to anti-lockdown protests.&lt;/p&gt;
&lt;p&gt;As a result of this work, we are literally writing the book (“The Big Book of Disinformation Response”), on how to respond to disinformation at scale in real time. This is part of our goal to make processes and learnings available to other teams.&lt;/p&gt;
&lt;h2 id=&#34;tools&#34;&gt;Tools&lt;/h2&gt;
&lt;p&gt;In order to focus on building the tools needed by the disinfo response groups we are fostering, we’ve handed over the AMITT Framework to the MITRE Corporation, to be managed alongside ATT&amp;amp;CK, their signature information security framework.  We’re using the modifications we made to STIX and MISP to build sharable rapid reports of disinformation incidents that include AMITT markups of tactics, techniques, and counters.&lt;/p&gt;
&lt;p&gt;We’ve extended MISP and its companion case-tracking software TheHive, to make them easier to use for disinformation reporting by adding new case workflow templates, new social media objects, and code to scrape and upload those objects to MISP using a single Slack bot command.&lt;br&gt;
With MISP repurposed to store disinformation, we launched the first MISP disinformation sharing community, bringing together a global network of researchers to share influence operation intelligence.  The Cognitive Security Collaborative MISP disinformation community is included by default in the MISP community release: access to it is available on request.&lt;/p&gt;
&lt;p&gt;We started building data collection and data science toolkits to make responses faster and easier. We continue to research and improve these core assets. We work with, learn from, and teach, a growing number of Threat Intelligence teams.&lt;/p&gt;
&lt;h2 id=&#34;the-next-6-months&#34;&gt;The Next 6 Months&lt;/h2&gt;
&lt;p&gt;As the COVID-19 pandemic continues and new challenges emerge, we have set new goals for ourselves:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;build a network of teams capable of responding to threats,&lt;/li&gt;
&lt;li&gt;keep merging with the Threat Intelligence world,&lt;/li&gt;
&lt;li&gt;continue building out the discipline of disinformation response by writing comprehensive documentation on countermeasures, narrative arcs, and disinformation response,&lt;/li&gt;
&lt;li&gt;normalize the inclusion of disinformation response as the standard for the information security profession.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To further these goals, we have registered the Cognitive Security Collaborative as a non-profit organization and applied for 501(c)3 status in the United States. This gives us a legal entity to act as a long-term custodian of our shared tools and knowledge, as well as a financial conduit for shared infrastructure, hosting, and development grants.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Right-wing Extremist Spotter&#39;s Guide</title>
      <link>https://www.cogsec-collab.org/post/right-wing-spotters-guide/</link>
      <pubDate>Wed, 17 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://www.cogsec-collab.org/post/right-wing-spotters-guide/</guid>
      <description>




  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/right-wing-spotters-guide/right-wing-spotter-1_hu7079205cb060331f723ff1859ab949d0_585584_2000x2000_fit_lanczos_2.png&#34; &gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/right-wing-spotters-guide/right-wing-spotter-1_hu7079205cb060331f723ff1859ab949d0_585584_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1100&#34; height=&#34;850&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;






  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/right-wing-spotters-guide/right-wing-spotter-2_hu209273f6398f08ec48f7589938b00a6e_372490_2000x2000_fit_lanczos_2.png&#34; &gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/right-wing-spotters-guide/right-wing-spotter-2_hu209273f6398f08ec48f7589938b00a6e_372490_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1100&#34; height=&#34;850&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cogsec-collab.org/files/Right-wing%20Extremist%20Spotter%27s%20Guide.pdf&#34; target=&#34;_blank&#34;&gt;Download PDF&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The New Old Power Projections</title>
      <link>https://www.cogsec-collab.org/post/new-old-power-projections/</link>
      <pubDate>Sun, 05 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://www.cogsec-collab.org/post/new-old-power-projections/</guid>
      <description>&lt;h1 id=&#34;the-old-new-cold-war&#34;&gt;The Old New Cold War&lt;/h1&gt;
&lt;p&gt;Cloaked by COVID-19 support, something troubling is happening. Cold War style soft power politics are being played, with nations making ostentatious displays of aid, or seizing medical supplies meant for others. This is the world stage, everyone is watching, and they will remember.&lt;/p&gt;
&lt;p&gt;Rapidly changing geopolitical power dynamics, combined with troubled federal response, has allowed for Cold War style soft power plays within Western countries. This is no longer the purview of just nationstates: it’s everyone from plutocrats, oligarchs, hackers, online influencers and Etsy makers. On the nationstate level, Russia and China are donating aid to Italy, American states are competing with each other and negotiating directly with China for basic critical medical supplies. State governors are openly praising&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; Chinese diplomats and plutocrats while the 
&lt;a href=&#34;https://www.msn.com/en-us/news/politics/german-official-accuses-us-of-wild-west-tactics-to-divert-shipment-of-masks/ar-BB128rlg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;US government steals medical equipment from its own states&lt;/a&gt;, and the WHO first ignored&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; Taiwan and then erased them (a deference to China that even the Washington Post&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; has adopted).  This sort of Cold War politicking used to happen in Lebanon or Somalia, now it&amp;rsquo;s happening in New York and Massachusetts.&lt;/p&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/new-old-power-projections/nygovcuomo_hub484450232d5f9b7f66db3e411874388_99554_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Source: https://twitter.com/NYGovCuomo/status/1246457007214931968?s=20&#34;&gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/new-old-power-projections/nygovcuomo_hub484450232d5f9b7f66db3e411874388_99554_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1204&#34; height=&#34;420&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Source: &lt;a href=&#34;https://twitter.com/NYGovCuomo/status/1246457007214931968?s=20&#34;&gt;https://twitter.com/NYGovCuomo/status/1246457007214931968?s=20&lt;/a&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;how-did-we-get-here&#34;&gt;How Did We Get Here?&lt;/h2&gt;
&lt;p&gt;Online influence operations, including disinformation campaigns, changed the way that nationstates interact with each other (see 
&lt;a href=&#34;https://www.cogsec-collab.org/authors/pablo_breuer/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pablo Breuer&amp;rsquo;s&lt;/a&gt; work on the new instruments of national power, aka 
&lt;a href=&#34;https://www.youtube.com/watch?v=7itYJ7EaK6c&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DIME models&lt;/a&gt;. Weakened nationstates like America that rely on power projection and had old unfixed fault lines across its population are particularly vulnerable; now we&amp;rsquo;re seeing nationstates moving in on the back of those campaigns, using aid the same way nations did during the Cold War, collecting allegiances and footholds whilst the last century&amp;rsquo;s big player is 
&lt;a href=&#34;https://www.codastory.com/%e2%80%a6/s%e2%80%a6/russia-coronavirus-aid-italy/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;too distracted to play&lt;/a&gt;, mixing &amp;ldquo;hearts and minds&amp;rdquo; physical moves with influence to change the balance of the world.&lt;/p&gt;
&lt;p&gt;There has to be a balance of power, or we&amp;rsquo;re all at the mercy of a handful of people halfway around the world. China plays the long game, Russia is opportunistic, and Europe is suffering another of a series of potentially Union busting crises.&lt;/p&gt;
&lt;p&gt;Collectively,  we can handle these issues by getting ahead of other ongoing and future emergencies around the world such as PPE, food availability, and economic instability. We need to push back against influence operations and see and manage these as part of a larger whole.&lt;/p&gt;
&lt;p&gt;We must also do what we can to mitigate the potential massive loss of life in less-equipped countries (makers - I hope you weren&amp;rsquo;t just designing for the US?) because it’s the right thing to do, and because providing medical equipment and PPE to other countries keeps them from becoming infection hotspots for the rest of the world.&lt;/p&gt;
&lt;h2 id=&#34;how-you-can-help&#34;&gt;How You Can Help&lt;/h2&gt;
&lt;p&gt;In case you think that&amp;rsquo;s just words, hell no. Now’s your chance to step up.&lt;/p&gt;
&lt;p&gt;Makers, hackers, disinfo experts, data scientists, friends running mutual aid networks: we&amp;rsquo;re all part of a massive grassroots effort to connect up and help protect each country as best we can. Countries are territory. Countries are people. Countries are image and power projections. Whatever is happening at the top of each country, it&amp;rsquo;s never greater than the people underneath it.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s time to see and be seen.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data scientists: you can help with the &amp;ldquo;see&amp;rdquo;: when you see stories about milk being poured away, start mapping dairies, trucks, processing plants and transport routes - rinse, repeat for everything you see that looks &amp;lsquo;wrong&amp;rsquo;.&lt;/li&gt;
&lt;li&gt;Disinformation experts - understand that your role isn&amp;rsquo;t just to find the campaigns, but also to understand where the &amp;lsquo;good&amp;rsquo; information is, and amplify it through local and crisis teams.&lt;/li&gt;
&lt;li&gt;Makers - also think about whether your designs can be adapted for places with limited resources.&lt;/li&gt;
&lt;li&gt;Mutual aid people: think about your local information environments and whether you can improve them (there are still concerted efforts to damage local news environments with e.g. fake local news sites - you might be one of the few strong voices in your area).&lt;/li&gt;
&lt;li&gt;Hackers: carry on doing your thing.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Someone said earlier that we&amp;rsquo;ve all been sent to our room to think about what we&amp;rsquo;ve done. We’ve had a think, now let&amp;rsquo;s get shit done!&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/nygovcuomo/status/1246457007214931968?s=21&#34;&gt;https://twitter.com/nygovcuomo/status/1246457007214931968?s=21&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://news.yahoo.com/taiwan-accuses-failing-heed-warning-143800176.html&#34;&gt;https://news.yahoo.com/taiwan-accuses-failing-heed-warning-143800176.html&lt;/a&gt; &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.washingtonpost.com/politics/infighting-missteps-and-a-son-in-law-hungry-for-action-inside-the-trump-administrations-troubled-coronavirus-response/2020/03/14/530c28b4-6559-11ea-b3fc-7841686c5c57_story.html&#34;&gt;https://www.washingtonpost.com/politics/infighting-missteps-and-a-son-in-law-hungry-for-action-inside-the-trump-administrations-troubled-coronavirus-response/2020/03/14/530c28b4-6559-11ea-b3fc-7841686c5c57_story.html&lt;/a&gt; &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Cogsec Collab MISP Community</title>
      <link>https://www.cogsec-collab.org/post/cogsec-misp-community/</link>
      <pubDate>Thu, 26 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://www.cogsec-collab.org/post/cogsec-misp-community/</guid>
      <description>&lt;h2 id=&#34;a-community-dedicated-to-information-operations&#34;&gt;A community dedicated to information operations&lt;/h2&gt;
&lt;p&gt;We&amp;rsquo;re proud to announce the CogSec Collab MISP Community - the first public MISP sharing group dedicated to misinformation and information campaigns.&lt;/p&gt;
&lt;p&gt;Our community seeks to connect misinformation researchers and responders  by providing tools to streamline investigation and reporting on  disinformation and information campaigns.  By making our MISP instance available to the community we&amp;rsquo;re enabling researchers to generate and share information operations data in MISP JSON or STIX format at just a click of a drop-down menu.&lt;/p&gt;
&lt;p&gt;We look forward to working with our partners to provide access to disinformation documentation and sharing standards, indicators, countermeasures and playbooks.&lt;/p&gt;
&lt;p&gt;Send us an email to request access.&lt;/p&gt;
&lt;h2 id=&#34;misp&#34;&gt;MISP&lt;/h2&gt;
&lt;p&gt;The MISP Project started out as a way to share malware indicators.  It&amp;rsquo;s grown to include much more - financial fraud, climate data and most recently COVID-19 cases.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;We have a dedicated MISP to share information about &lt;a href=&#34;https://twitter.com/hashtag/COVID2019?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#COVID2019&lt;/a&gt; &lt;a href=&#34;https://t.co/64bWDpZAKr&#34;&gt;https://t.co/64bWDpZAKr&lt;/a&gt; - If you want access DM us on Twitter. &lt;a href=&#34;https://t.co/8KuykC3XE0&#34;&gt;pic.twitter.com/8KuykC3XE0&lt;/a&gt;&lt;/p&gt;&amp;mdash; MISP (@MISPProject) &lt;a href=&#34;https://twitter.com/MISPProject/status/1239864641993551873?ref_src=twsrc%5Etfw&#34;&gt;March 17, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;p&gt;At its core MISP is an automated correlation engine.  It assists analysts in finding interesting relationships between indicators and contextualising the data. For Cogsec Collab, it&amp;rsquo;s a means to provide structured threat intelligence to cross-sector partners with highly diverse requirements.&lt;/p&gt;
&lt;h2 id=&#34;amtt-misinformation-pattern-galaxy&#34;&gt;AM!TT Misinformation Pattern Galaxy&lt;/h2&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/cogsec-misp-community/galaxy_list_hu2dbb63b19e88e7c410a1d20e6ac2c179_164943_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Descriptions of AMITT Techniques in the MISP Misinformation Pattern Galaxy.&#34;&gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/cogsec-misp-community/galaxy_list_hu2dbb63b19e88e7c410a1d20e6ac2c179_164943_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1409&#34; height=&#34;1034&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Descriptions of AMITT Techniques in the MISP Misinformation Pattern Galaxy.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Our first achievement  was the integration of the 
&lt;a href=&#34;https://github.com/misinfosecproject/amitt_framework&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AM!TT Framework&lt;/a&gt; as a 
&lt;a href=&#34;https://www.misp-project.org/galaxy.html#_misinformation_pattern&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MISP Galaxy&lt;/a&gt;.  It contains the tags and definitions needed for describing the misinformation tactics and techniques present in a specific information operation.&lt;/p&gt;
&lt;h2 id=&#34;amtt-navigatord&#34;&gt;AM!TT Navigatord&lt;/h2&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/cogsec-misp-community/amitt_hubdc8e6b1c15d4bf18fbc9d921a0e6520_204170_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;The MISP Project kindly developed this built-in technique navigator.&#34;&gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/cogsec-misp-community/amitt_hubdc8e6b1c15d4bf18fbc9d921a0e6520_204170_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;2006&#34; height=&#34;1012&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    The MISP Project kindly developed this built-in technique navigator.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Applying the AM!TT galaxy information to an event must be easy in order to encourage use by already overburdened information researchers.  The MISP Project developers kindly created an inline AM!TT Navigator to respond to this need for conveniently tagging events with AM!TT techniques.&lt;/p&gt;
&lt;p&gt;With this tool, analysts can simply click on the relevant techniques found in a report or sighting to include that information in the misinformation event data.&lt;/p&gt;
&lt;h2 id=&#34;dfrlab-dichotomies-of-disinformation&#34;&gt;DFRLab Dichotomies of Disinformation&lt;/h2&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/cogsec-misp-community/dfrlab_huc1a7678efde9b01802178e4c130b4025_137500_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Atlantic Council&amp;rsquo;s DFRLab Dichotomies of Disinformation&#34;&gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/cogsec-misp-community/dfrlab_huc1a7678efde9b01802178e4c130b4025_137500_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1976&#34; height=&#34;726&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Atlantic Council&amp;rsquo;s DFRLab Dichotomies of Disinformation
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Also included in the CogSec Collab MISP is 
&lt;a href=&#34;https://www.atlanticcouncil.org/programs/digital-forensic-research-lab/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Atlantic Council&amp;rsquo;s DFRLab&lt;/a&gt; 
&lt;a href=&#34;https://github.com/DFRLab/Dichotomies-of-Disinformation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dichotomies of Disinformation&lt;/a&gt; which is a new standard for describing information campaigns that can be used alone or in complement to the AM!TT framework.&lt;/p&gt;
&lt;p&gt;The work of the DFRLab is included in MISP as a Taxonomy - a set of machine tags for describing indicators and events.&lt;/p&gt;
&lt;h2 id=&#34;future-work&#34;&gt;Future Work&lt;/h2&gt;
&lt;p&gt;From this point our next steps are to  build elf communities and equip them with the tooling and  training needed to be effective.&lt;/p&gt;
&lt;p&gt;MISP will play an important role in distributing misinformation threat data but it&amp;rsquo;s just a tool; it&amp;rsquo;s the people who make the community of users that can make it great.  If you work in the disinformation space, please reach out.  Come talk to us.&lt;/p&gt;
&lt;p&gt;As things develop we&amp;rsquo;ll have more to say about our disinformation sharing community.  For now we&amp;rsquo;d like to thank the 
&lt;a href=&#34;https://twitter.com/MISPProject&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MISP Project&lt;/a&gt; developers for their excellent work and commitment to FOSS threat intelligence tooling.&lt;/p&gt;
&lt;p&gt;Thank you!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The MisinfosecWG Counters Workshop</title>
      <link>https://www.cogsec-collab.org/post/misinfosecwg-counters/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://www.cogsec-collab.org/post/misinfosecwg-counters/</guid>
      <description>&lt;h2 id=&#34;the-misinfosec-working-group&#34;&gt;The Misinfosec Working Group&lt;/h2&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/misinfosecwg-counters/misinfosec1_hu75ed1ec14814cd4cad3be534472fd0e7_233215_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;MisinfosecWG timeline. We built infosec-based standards for describing and sharing information about disinformation incidents&#34;&gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/misinfosecwg-counters/misinfosec1_hu75ed1ec14814cd4cad3be534472fd0e7_233215_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;840&#34; height=&#34;436&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    MisinfosecWG timeline. We built infosec-based standards for describing and sharing information about disinformation incidents
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;The Misinfosec Working Group (“misinfosecWG”) is part of the Credibility Coalition. It was formed around a standard for action: we wanted a way for the many groups and individuals that we saw starting to investigate disinformation incidents to quickly share information about them, in the same ways that information security groups share information through information exchanges like ISACs and ISAOs, and disclosure schemes like bug bounties. We also wanted, as the field of disinformation response grew, to build ways for groups and individuals to quickly look up and share information about the mitigations and other activities that worked (or might work) to counter active disinformation campaigns.&lt;/p&gt;
&lt;p&gt;MisinfosecWG has come a long way since Pablo and I talked in 2018 about creating standards for misinfosec — the application of information security principles and practices to disinformation incident mitigation — and decided that CredCo was the only obvious place to incubate such a standards group. Walker and I started the CredCo misinfosec working group in December 2018, and since its official launch in January 2019, we’ve built a bridge between information security, misinformation and specialists in fields like narrative science (looking at you, John, Walker and Danielle), placed infosec-style response firmly inside disinformation response, and adapted existing infosec standards like ATT&amp;amp;CK and STIX into the AMITT standard for disinformation use, giving us the ability to transmit, share and analyze information about disinformation using existing information security technologies and techniques.&lt;/p&gt;
&lt;p&gt;And in November 2019, MisinfosecWG ran the second of its workshops; the “Blue Team Workshop” on misinformation countermeasures. The last of these, the “Red Team Workshop”, in Atlanta, modeled the tactics and techniques used by disinformation creators, and produced the AMITT framework of disinformation tactics, techniques and procedures (TTPs). The DC workshop, held in the Atlantic Council’s meeting space, focused on how responders could mitigate and counter those TTPs.&lt;/p&gt;
&lt;h2 id=&#34;why-run-a-countermeasures-workshop&#34;&gt;Why Run a Countermeasures Workshop?&lt;/h2&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/misinfosecwg-counters/misinfosec2_hu56ca49df1032328068b0c44ed177dd9f_228657_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;A STIX diagram for a disinformation incident. The workshop was about creating more of the green box on the right (courses of action to counter incidents, techniques, tactics etc)&#34;&gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/misinfosecwg-counters/misinfosec2_hu56ca49df1032328068b0c44ed177dd9f_228657_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;896&#34; height=&#34;589&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    A STIX diagram for a disinformation incident. The workshop was about creating more of the green box on the right (courses of action to counter incidents, techniques, tactics etc)
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;MisinfosecWG has always had two main aims: to promote a more formal and rigorous classification of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Types of information-based attacks; and&lt;/li&gt;
&lt;li&gt;Types of defense from information-based attacks&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We’d already covered the first bullet with our work on AMITT and STIX-based descriptions of disinformation TTPs. This workshop was all about our work on the second bullet: defense, and in particular, disinformation counters, mitigations and other potential responses.&lt;/p&gt;
&lt;p&gt;Countering disinformation is a multi-disciplinary activity, so we enlisted experts on disinformation, cognitive security, information security, narrative and rumor tracking, diplomacy, trust and safety, counterterrorism and CVE from our target user communities: industry, academia, media, community, government and military. We stated the workshop goals up front:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Draft a disinformation “Blue Team” playbook. Its intended users are defenders, information security people and organizations; its contents should be a set of responses to misinformation attacks, with information on networks, response types, frameworks, examples.&lt;/li&gt;
&lt;li&gt;Ideate supporting an operational global Cognitive Security response network. The audience for this is potential response centre participants and leaders, and its contents should be a set of processes, methods, understanding needed to connect actors, partners, collaborators and funders.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And we framed the first solution space by combining the stages that a disinformation incident goes through (its “tactics”) from AMITT with the types of action that could block or mitigate each of them (courses of action categories) to create an empty ‘grid’ on the wall.&lt;/p&gt;
&lt;p&gt;Our aim in the workshop was to fill this grid with potential responses, then drill down into the details of some of those responses. First, level-setting. With all the different disciplines in the room, we used the AMITT framework and misinfosec pyramid (campaigns/ incidents/ narratives/ artefacts) to frame the work we were doing, including the idea that each object in the STIX graphs we create for each disinformation incident could potentially be paired with a course of action (the green icon, defined in information security as “an action taken to either prevent an attack or respond to an attack”) to mitigate, block or disable it, and that the ATT&amp;amp;CK idea of finding counters for each technique (the blue icons) was a good place to start.&lt;/p&gt;
&lt;h2 id=&#34;existing-counters&#34;&gt;Existing Counters&lt;/h2&gt;
&lt;p&gt;We didn’t go empty-handed to the workshop. The MisinfosecWG team had already spent time looking for counters in our set of example incidents (in the AMITT GitHub repository), and looking at existing counter examples and types through a combination of existing knowledge and literature search (e.g. in the DoJ’s framework). Some well-known examples we gave of these are below, but we also encouraged attendees to think laterally about countering the techniques that they saw:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;US Cyber Command blocking internet services to the Internet Research Agency on the day of the 2018 US Midterm elections&lt;/li&gt;
&lt;li&gt;Twitter killing a pro-Saudi botnet spreading Khashoggi disinformation tweets&lt;/li&gt;
&lt;li&gt;Macron’s team creating data honeypots before French elections&lt;/li&gt;
&lt;li&gt;CISA’s “War on Pineapple” education sheets about disinformation&lt;/li&gt;
&lt;/ul&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/misinfosecwg-counters/misinfosec3_hu5c8d536cbadde37be653e4204eeed0a7_130142_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;AMITT Tactics and Techniques — see https://github.com/misinfosecproject/amitt_framework&#34;&gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/misinfosecwg-counters/misinfosec3_hu5c8d536cbadde37be653e4204eeed0a7_130142_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;960&#34; height=&#34;540&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    AMITT Tactics and Techniques — see &lt;a href=&#34;https://github.com/misinfosecproject/amitt_framework&#34;&gt;https://github.com/misinfosecproject/amitt_framework&lt;/a&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;We needed to frame these — to structure them so they weren’t a random collection of examples and suggestions. So we used AMITT’s TTPs (Tactics, Techniques, Procedures).&lt;/p&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/misinfosecwg-counters/misinfosec4_huee445b559b3fcd8cb4517854cfc4d6fd_32595_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Courses of Action grid for AMITT tactics&#34;&gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/misinfosecwg-counters/misinfosec4_huee445b559b3fcd8cb4517854cfc4d6fd_32595_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;731&#34; height=&#34;377&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Courses of Action grid for AMITT tactics
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;AMITT breaks disinformation incidents down into tactic stages. In infosec, when you map those tactics against the types of action that could be taken against each tactic stage, you get a Courses of Action matrix.&lt;/p&gt;
&lt;p&gt;We used the JP 3–13 (2006 US military Joint Publication 3–13 on information operations) definitions for our action categories; there are many of these, but we used the subset of Detect, Deny, Disrupt, Degrade, Deceive and Destroy, adding “Deter” to the list.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Detect: discover or discern the existence, presence, or fact of an intrusion into information systems.&lt;/li&gt;
&lt;li&gt;Deny: prevent the adversary from accessing and using critical information, systems, and services.&lt;/li&gt;
&lt;li&gt;Disrupt: break or interrupt the flow of information.&lt;/li&gt;
&lt;li&gt;Degrade: reduce the effectiveness or efficiency of adversary command and control or communications systems, and information collection efforts or means.&lt;/li&gt;
&lt;li&gt;Deceive: cause a person to believe what is not true. military deception seeks to mislead adversary decision makers by manipulating their perception of reality.&lt;/li&gt;
&lt;li&gt;Destroy: damage a system or entity so badly that it cannot perform any function or be restored to a usable condition without being entirely rebuilt.&lt;/li&gt;
&lt;li&gt;Deter: discourage&lt;/li&gt;
&lt;/ul&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/misinfosecwg-counters/misinfosec5_hub204b382a852c12763076b8144dd708e_79317_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;SANS scale for counters&#34;&gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/misinfosecwg-counters/misinfosec5_hub204b382a852c12763076b8144dd708e_79317_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;789&#34; height=&#34;358&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    SANS scale for counters
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;We also talked about counters in the context of the SANS scale from architectural through to offensive countermeasures.&lt;/p&gt;
&lt;h2 id=&#34;brainstorming-a-courses-of-action-wall&#34;&gt;Brainstorming a Courses of Action wall&lt;/h2&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/misinfosecwg-counters/misinfosec6_hu9f4e76bcf8570a1e7d291a08644122e1_193266_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;Courses of Action starting to fill up. Note the blank boxes in it, where we might need more work&#34;&gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/misinfosecwg-counters/misinfosec6_hu9f4e76bcf8570a1e7d291a08644122e1_193266_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1600&#34; height=&#34;900&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Courses of Action starting to fill up. Note the blank boxes in it, where we might need more work
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;And then it was post-its time. We split into groups, and each group took a set of tactic columns to work on, and a large stack of blank post-its. They didn’t disappoint. The wall filled up (the wall rows were courses of action; the columns were AMITT tactic stages).&lt;/p&gt;
&lt;p&gt;We had a wide range of ideas back from the groups. Because we forced people to think about countering the whole disinformation lifecycle, from strategic planning all the way through to after-action evaluations, we think we captured counters that haven’t been tried before, many of which are in the valuable “left-of-boom” area before a campaign reaches the general public.&lt;/p&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/misinfosecwg-counters/misinfosec7_huce7da389b299a9c23990551586ffe07c_284344_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;Course of Action box for “Detect” on tactic “Develop Content”&#34;&gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/misinfosecwg-counters/misinfosec7_huce7da389b299a9c23990551586ffe07c_284344_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1600&#34; height=&#34;900&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Course of Action box for “Detect” on tactic “Develop Content”
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;A post-it on a wall isn’t a response, so we asked teams to drill further into each set of counters — looking at who could take each action, how it might play out, what its side-effects might be. That produced a lot more detail, and yet more counters, all of which were added to a prototype technique-level playbook.&lt;/p&gt;
&lt;h2 id=&#34;thinking-about-end-users&#34;&gt;Thinking about End Users&lt;/h2&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/misinfosecwg-counters/misinfosec8_hud30bd7d8c682bb32aba07ac298a9925a_99661_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;ISACs — just some of the bodies connected to the Cognitive Security ISAO&#34;&gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/misinfosecwg-counters/misinfosec8_hud30bd7d8c682bb32aba07ac298a9925a_99661_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;568&#34; height=&#34;352&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    ISACs — just some of the bodies connected to the Cognitive Security ISAO
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Disinformation is a whole-system problem, and we took the opportunity to spend some time preparing for the next activity needed — coordinating whole-system response through bodies like the US ISAO system, and more specifically the prototype Cognitive Security ISAO, looking at what they do and how we as a group could support them.&lt;/p&gt;
&lt;h2 id=&#34;making-counters-useful&#34;&gt;Making Counters Useful&lt;/h2&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/misinfosecwg-counters/misinfosec9_hu9187501edcb887bf1c21223226b1c90e_134066_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Counters organised by metatag — see https://github.com/misinfosecproject/amitt_counters&#34;&gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/misinfosecwg-counters/misinfosec9_hu9187501edcb887bf1c21223226b1c90e_134066_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1854&#34; height=&#34;1448&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Counters organised by metatag — see &lt;a href=&#34;https://github.com/misinfosecproject/amitt_counters&#34;&gt;https://github.com/misinfosecproject/amitt_counters&lt;/a&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;And then the workshop was done, but we’re not finished yet. We created a spreadsheet from the courses of action grid. After consolidating identical ideas, we have nearly 200 counters to analyze and make useful, plus suggested additions to AMITT etc.&lt;/p&gt;
&lt;p&gt;MisinfosecWG has finished its incubation year with CredCo, and the team has created and is now working in a new community, 
&lt;a href=&#34;https://www.cogsec-collab.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CogSec Collab&lt;/a&gt;, that’s concentrating on supporting disinformation volunteer groups and individuals.&lt;/p&gt;
&lt;p&gt;We’re still organising the counters. We have them tagged with tactic, techniques, groups who could be write up in our responses. We grouped by ‘metatags’: tags for similar activities, til we realised that that was a proxy for a top-down activity and started describing that instead. We have two reports in the works: one on how we found and organised counters, and another on the counters themselves. Roger and Eric are busy adapting ATT&amp;amp;CK technologies to carry the AMITT responses and playbook entries that we’re building. It’s going to take us a little while, but we’re still slowly moving forwards with misinfosec.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The MisinfoSec Framework Takes Shape</title>
      <link>https://www.cogsec-collab.org/post/misinfosecwg-framework-takes-shape/</link>
      <pubDate>Fri, 19 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://www.cogsec-collab.org/post/misinfosecwg-framework-takes-shape/</guid>
      <description>&lt;h2 id=&#34;developing-the-amitt-adversarial-misinformation-and-influence-tactics-and-techniques-framework&#34;&gt;Developing the AMITT (Adversarial Misinformation and Influence Tactics and Techniques) framework&lt;/h2&gt;
&lt;p&gt;By 
&lt;a href=&#34;https://twitter.com/grayspective&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;John Gray&lt;/a&gt; and 
&lt;a href=&#34;https://twitter.com/bodaceacat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sara-Jayne Terp&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;On May 24, 2019, the CredCo MisinfoSec Working Group met for the day at the Carter Center in as part of CredConX Atlanta. The purpose of the day was to draft a working MisinfoSec framework that incorporates the stages and techniques of misinformation, and the responses to it. We came up with a name for our framework: AMITT (Adversarial Misinformation and Influence Tactics and Techniques) provides a framework for understanding and responding to organized misinformation attacks based on existing information security principles.&lt;/p&gt;
&lt;p&gt;We’d like to provide a recap of what the working group came up with the day, as well as explain and discuss some of the key concepts we used to inform our work. It should be noted that the working group relied on 
&lt;a href=&#34;https://misinfocon.com/misinformation-has-stages-7e00bd917108&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;our previous work on the stages of misinformation&lt;/a&gt;, documented in a previous Misinfocon blog post.&lt;/p&gt;
&lt;h2 id=&#34;who-we-are-and-what-we-do&#34;&gt;Who We Are and What We Do&lt;/h2&gt;
&lt;p&gt;Before we describe what we accomplished at the Carter Center in Atlanta on May 24, it’s a good idea to briefly explain who we are and the formal mission of the MisinfoSec Working Group:
The Credibility Coalition’s MisinfoSec Working Group (“MisinfoSec WG”) maps information security (infosec) principles onto misinformation. According to the The CredCo Misinfosec Working Group 
&lt;a href=&#34;https://github.com/credcoalition/community-site/wiki/MisinfoSec-%28The-Intersection-of-Misinformation-and-InfoSec%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;charter&lt;/a&gt;, our goal is to develop a tactics, techniques and procedures (TTP) based framework that gives misinformation researchers and responders a common language to discuss and disrupt misinformation incidents.&lt;/p&gt;
&lt;p&gt;Our working group is also focused on contributing to the evolution of MisinfoSec as a discipline. This evolution is happening, as we’re seeing an emergence of presentations with slides referring to TTPs, and people starting to talk about building 
&lt;a href=&#34;https://www.isao.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ISAOs&lt;/a&gt; (Information Sharing and Analysis Organizations) and 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Information_Sharing_and_Analysis_Center&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ISACs&lt;/a&gt; (Information Sharing and Analysis Centers) — non-profit organizations that provide a coordinated central hub for gathering and sharing of cyber threat information for the US Government, specifically in relationship to misinformation.&lt;/p&gt;
&lt;h2 id=&#34;establishing-a-common-language-for-communicating-threats&#34;&gt;Establishing a Common Language for Communicating Threats&lt;/h2&gt;
&lt;p&gt;In order to coordinate misinformation response centers with each other, and share information easily, they’re going to need information-sharing standards for misinformation.
So, a key goal of our working group is to promote more formal, practical and rigorous treatment of types of information-based attacks, and types of defense from information-based attacks.
The working group’s deliverables will include a text resource consisting of definitions and a strawman framework combining the elements above, and an online article highlighting some common attacks in the wild.&lt;/p&gt;
&lt;p&gt;So far, since January 2019, the group’s imperative has been to establish a common language for communicating about and responding to dynamic threats creating complex problems.
It’s equally important to help lead the effort to ensure that MisinfoSec (applying information security paradigms to misinformation campaigns) plays a key role in every conversation about cognitive security and information system resilience.&lt;/p&gt;
&lt;p&gt;While we’re building upon 
&lt;a href=&#34;https://medium.com/1st-draft/information-disorder-part-1-the-essential-glossary-19953c544fe3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;existing definitions of the (mis)information ecosystem&lt;/a&gt;, the Misinfo Working Group is also working at evolving the language and discipline. Acknowledging that 
&lt;a href=&#34;https://misinfocon.com/kermit-is-credible-and-this-is-good-for-news-f26f595a356e&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;‘credibility’ can be definitely be recognized and identified&lt;/a&gt;, and with an aim of providing more nuance to how coordinated misinformation is defined, [the following definitions](the following definitions) served as a foundation:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Disinformation&lt;/strong&gt;: False information that is deliberately created or disseminated with the express purpose to cause harm. Producers of disinformation typically have political, financial, psychological or social motivations.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Misinformation&lt;/strong&gt;: Information that is false, but not necessarily intended to cause harm. For example, individuals who don’t know a piece of information is false may spread it on social media in an attempt to be helpful.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Malinformation&lt;/strong&gt;: Genuine information that is shared to cause harm.This includes private or revealing information that is spread to harm a person or reputation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;With these concepts and assumptions in mind, our working group operates according the definition of misinformation attack that we defined in 
&lt;a href=&#34;https://dl.acm.org/citation.cfm?id=3316742&amp;amp;dl=ACM&amp;amp;coll=DL&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Misinfosec: Applying Information Security Paradigms to Misinformation Campaigns&lt;/a&gt; (2019) by Christopher R. Walker, Sara-Jayne Terp and Pablo C. Breuer:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;We use ‘misinformation attack’ (and ‘misinformation campaign’) to refer to the deliberate promotion of false, misleading or mis-attributed information […] We are especially interested in misinformation designed to change beliefs in a large number of people.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Actors behind misinfo attacks include nation-states, institutional actors, grassroots trolls and financially-motivated freelancers. Common motives include geopolitical aims, issue-promotion or financial gain.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;our-task-in-atlanta-building-a-misinfosec-framework&#34;&gt;Our Task in Atlanta: Building a MisinfoSec Framework&lt;/h2&gt;
&lt;p&gt;So, on May, 25, the MisinfoSec Working Group assembled at CredConX in Atlanta to build a framework. The meeting room at the Carter Center was like our lab for the day. And, while our efforts were not in the league of 
&lt;a href=&#34;https://www.sciencehistory.org/historical-profile/frederick-banting-charles-best-james-collip-and-john-macleod&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Banting and Best&lt;/a&gt; whose discovery of insulin improved the lives of millions of people with diabetes, we found a striking parallel.&lt;/p&gt;
&lt;p&gt;To use a metaphor, the problems plaguing today’s information ecosystem is like diabetes.&lt;/p&gt;
&lt;p&gt;As 
&lt;a href=&#34;https://www.linkedin.com/in/randwaltzman/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Rand Waltzman&lt;/a&gt; and 
&lt;a href=&#34;https://twitter.com/noUpside&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Renee DiResta&lt;/a&gt; have noted, “Disinformation is a not a problem that can be solved. It’s like a chronic disease that can be managed — not cured- allowing the afflicted to lead a moderately normal life.”&lt;/p&gt;
&lt;p&gt;As we worked together at the Carter Center, on May 24, we were able to build upon the following our team’s existing work:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A strawman framework we created for the 
&lt;a href=&#34;https://www2019.thewebconf.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Web Conference MisInfoWorkshop2019 talk&lt;/a&gt; — not detailed, with a set of stages that were designed to be argued about. The paper is “Applying Information Security Paradigms to Misinformation Campaigns.” See 
&lt;a href=&#34;https://www.youtube.com/watch?v=nzQWbTOdAAE&amp;amp;t=3735s&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;our colleague Christopher Walker’s presentation here starting at the 1:00:00 mark&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A mapping of marketing, psyops and new misinformation stage models against the cyber killchain.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The 
&lt;a href=&#34;https://misinfocon.com/misinformation-has-stages-7e00bd917108&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;misinformation pyramid&lt;/a&gt;, so we could talk about the different viewpoints of attackers (red team) and defenders (blue team)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://medium.com/@timboucher/adversarial-social-media-tactics-e8e9857fede4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Boucher’s list of techniques&lt;/a&gt;, mapped onto 
&lt;a href=&#34;https://twitter.com/benimmo/status/670230827377295360?lang=en-gb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ben Nimmo’s “5 D’s” strategies&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;An example of each of the stage-based frameworks we’d compared earlier in the day&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A list of the existing ISACs (Information Sharing and Analysis Centers), so we remembered who we’re trying to support&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/misinfosecwg-framework-takes-shape/misinfosec1_hufbe71ff2bfa72833c08d95b72d88d639_226169_2000x2000_fit_q90_lanczos.jpeg&#34; &gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/misinfosecwg-framework-takes-shape/misinfosec1_hufbe71ff2bfa72833c08d95b72d88d639_226169_2000x2000_fit_q90_lanczos.jpeg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;900&#34; height=&#34;897&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Our meeting goal at the Carter Center in Atlanta was to build a framework of misinformation, stages, techniques and responses. In particular, the Working Group gathered to further solidify our work (since March 2019) on developing framework stages and technique templates for incident responders by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Increasing our set of techniques&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Mapping techniques to stages&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Solidifying stage labels&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Documenting potential technique responses&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To do this, in Atlanta the Working Group came equipped with these common terms of reference:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;A technique&lt;/strong&gt;: Deployed by 
&lt;a href=&#34;https://securingdemocracy.gmfus.org/advanced-persistent-manipulators-part-one-the-threat-to-the-social-media-industry/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Advanced Persistent Manipulators&lt;/a&gt;, can include relatively benign approaches, such as the use of humour and rhetoric, all the way through to the forging of documents or the use of false identities.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;A stage-based model&lt;/strong&gt;: Similar to the Cyber Kill Chain. We’ve previously outlined our premise about 
&lt;a href=&#34;https://misinfocon.com/misinformation-has-stages-7e00bd917108&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;misinformation as a process of stages&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;A response&lt;/strong&gt;: There is no definitive collection of best-practices or playbook of successful counteractions. The MisinfoSec Working Group has defined a response as one step of a strategic process, a holistic one that starts with assessing a technique in the context of seeing it as part of a chain-of-events. With an evolving playbook we agree with 
&lt;a href=&#34;https://twitter.com/selectedwisdom&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Clint Watts’&lt;/a&gt; current position that “the goal is to take an approach that will anticipate changes in threat behavior and proactively disrupt nefarious activity rather than reactively respond to it.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;the-first-task-grouping-techniques-for-spreading-misinformation&#34;&gt;The First Task: Grouping Techniques for Spreading Misinformation&lt;/h2&gt;
&lt;p&gt;Before the session, we prepared by listing the techniques used in each of our list of incidents, then created a post-it for each technique. Each technique post-it held an incident number and description, with techniques from incidents attributed to Russia documented on blue post-its, yellow post-its for non-Russia attribution.
For the next step, we gathered all of the post-its, and then invited meeting attendees to cluster them into stages (pink post-it notes), and order the stages on a wall from left (campaign/incident planning) to right (campaign/incident completion).
Mapping the wall was a process of grouping identical techniques into stacks, and talking through the stages, discussing what belonged where in the order.&lt;/p&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/misinfosecwg-framework-takes-shape/misinfosec2_hu48192afc48c725dd07ea8148fbd9f681_188062_2000x2000_fit_q90_lanczos.jpeg&#34; &gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/misinfosecwg-framework-takes-shape/misinfosec2_hu48192afc48c725dd07ea8148fbd9f681_188062_2000x2000_fit_q90_lanczos.jpeg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1600&#34; height=&#34;900&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Satisfied with this first exercise, we revisited 
&lt;a href=&#34;https://misinfocon.com/misinformation-has-stages-7e00bd917108&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;our collection of existing models&lt;/a&gt; (ATT&amp;amp;CK model, marketing funnels, psyops, Department of Justice model), and models from Renée diResta, Ben Decker, Clint Watts and Bruce Schneier. We investigated whether their respective stages and techniques were represented in our model on the wall, and if not, added them. Surprises included that the 
&lt;a href=&#34;https://www.lawfareblog.com/toward-information-operations-kill-chain&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;stages in the New York Times model&lt;/a&gt; (used by Bruce Schneier) were actually techniques (more on this in a subsequent blog post).
Having established a model, we needed to test it. We spent just over an hour adopting a “red team” (attacker) mindset in order to build an imaginary misinformation campaign. It was invaluable walking through each stage (see Sara-Jayne Terp’s 
&lt;a href=&#34;https://misinfocon.com/misinformation-has-stages-7e00bd917108&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Misinformation has stages&lt;/a&gt; blog post for more details) to see whether we’d missed anything.&lt;/p&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/misinfosecwg-framework-takes-shape/misinfosec3_hue35e23061a68ce2bd83892e689d8b7a6_308861_2000x2000_fit_q90_lanczos.jpeg&#34; &gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/misinfosecwg-framework-takes-shape/misinfosec3_hue35e23061a68ce2bd83892e689d8b7a6_308861_2000x2000_fit_q90_lanczos.jpeg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;900&#34; height=&#34;1402&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;No surprise, we had missed a few details, and so took the opportunity to add both stages and new techniques as we walked through the exercise.&lt;/p&gt;
&lt;h2 id=&#34;the-next-task-developing-techniques-to-combat-misinformation&#34;&gt;The Next Task: Developing Techniques to Combat Misinformation&lt;/h2&gt;
&lt;p&gt;With a tested model, after we transferred all of the information into a new spreadsheet, we were ready to dive into individual techniques. As part of this next stage of our work, we looked at techniques both individually and as part of a process, and we spent time thinking about how we could counter or disrupt them.&lt;/p&gt;
&lt;p&gt;Given our time constraints, we focused on techniques that had amassed the most post-its during our previous exercise. More post-its meant the techniques were typically used in multiple incidents, such as fake Facebook group and Twitter bots and trolls.&lt;/p&gt;
&lt;p&gt;At this stage, some additional discussions, which lead to useful pointers, included:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Think in terms of feedback loops, rather than linear processes&lt;/strong&gt;: While we might have a linear stage model, what we’re really observing are cycles and feedback loops (which is already built into ATT&amp;amp;CK Adversarial Tactics, Techniques, and Common Knowledge).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Look for both content and context&lt;/strong&gt;: The network-building stage is about creating the context of a campaign; the content creation stage is about creating the content for it. These concepts both map nicely to our blue team idea of looking for both content and context.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Ask who is leading a misinformation campaign&lt;/strong&gt;: We looked at how adversaries use metrics and measurement, and plan or deploy countermeasures. Is it implicit that there’s a “general manager” watching over the campaign, checking metrics and so on?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Understand different levels of defence&lt;/strong&gt;: The working group looked at technique-level defence vs procedure-level defences (e.g. disrupting the chain of work), and doing that as far left in the stage diagram as possible. For example, we looked at how online or digital network building looks like a good location to disrupt, or getting inside the organisational places for doing both recon and delivering counters.&lt;/p&gt;
&lt;/blockquote&gt;





  
  











&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://www.cogsec-collab.org/post/misinfosecwg-framework-takes-shape/misinfosec4_hu4de1059576c90fac47d090c92a34721b_381552_2000x2000_fit_q90_lanczos.jpeg&#34; &gt;


  &lt;img data-src=&#34;https://www.cogsec-collab.org/post/misinfosecwg-framework-takes-shape/misinfosec4_hu4de1059576c90fac47d090c92a34721b_381552_2000x2000_fit_q90_lanczos.jpeg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;900&#34; height=&#34;1145&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h2 id=&#34;dont-forget-the-boom&#34;&gt;Don’t Forget the Boom!&lt;/h2&gt;
&lt;p&gt;And, during the day at the Carter Center, we didn’t forget the “boom,” a term borrowed from the military meaning the moment before 
&lt;a href=&#34;https://www.urbandictionary.com/define.php?term=a%20bomb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;a bomb&lt;/a&gt; explodes (as opposed to “right-of-boom”, which comes after). In particular we’re very interested in working towards the disruption, denial and displacement of the left-of-boom techniques.&lt;/p&gt;
&lt;h1 id=&#34;whats-next-for-credcos-misinfosec-wg&#34;&gt;What’s Next for CredCo’s MisinfoSec WG&lt;/h1&gt;
&lt;p&gt;By the end of our working session at CredConX at the Carter Center in Atlanta on May 24, we successfully created AMITT (Adversarial Misinformation and Influence Tactics and Techniques), a preliminary MisinfoSec framework that included stages, techniques and responses. Next, the working group needs to test it with different demographics, continue the counter-discussions and support the new ISAOs as they come online. As well, stay tuned for our June report — our goal is to have Version 1.0 online by the end of July.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Participants at the May 24 session in Atlanta included Sara-Jayne Terp, Christopher Walker, John Gray, Courtney Crooks, Chau Tong and Renee DiResta. Working group member Pablo Breuer was absent for the day. Many thanks to them and to our guests — Amy Bruckman, Benn Konsynski, Richard Foard, David Carroll, Michael Best, Nitin Agarwal and Tanushree Mitra — for their thoughts and input.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
